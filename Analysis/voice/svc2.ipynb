{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svc训练方案2.0\n",
    "\n",
    "### 训练时对yzc训练集进行大batch的采样，测试时对测试集进行小batch的采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import os.path as path\n",
    "from tqdm import tqdm as progress\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_MS_RATIO = 0.09380235476687636 # frames per milisecond\n",
    "offset = int(2000 * FRAME_MS_RATIO) # offset of subsampling, in frames (2s in this eg.)\n",
    "duration = int(6000 * FRAME_MS_RATIO) # maximun length of subsampling range, in frames\n",
    "unit = int(80 * FRAME_MS_RATIO) # length of a single subsample, in frames\n",
    "stride = unit // 2 # step in frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling from `.ftr` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO support\n",
    "def load_from_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def save_to_file(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def suffix_filter(files, suffix):\n",
    "    '''\n",
    "    return list of files with given suffix\n",
    "    '''\n",
    "    return filter(lambda x: x.endswith(suffix), files)\n",
    "\n",
    "def show_shape(obj):\n",
    "    return np.array(obj).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(mfcc: object, offset, duration, unit, stride=None):\n",
    "    '''\n",
    "    mfcc: shape like (40, xxx)\n",
    "    return: list of subsamples\n",
    "    '''\n",
    "    if stride is None: stride = unit // 2\n",
    "    subsamples = []\n",
    "    high = offset + duration\n",
    "    left = offset\n",
    "    right = left + unit\n",
    "    while right <= high:\n",
    "        subsamples.append(mfcc[:, left : right])\n",
    "        left += stride\n",
    "        right += stride\n",
    "    return subsamples\n",
    "\n",
    "def get_batches(subsamples, batch_size):\n",
    "    '''\n",
    "    batch-size is suggested to be an odd number\n",
    "    return a list of test-batches from subsamples\n",
    "    '''\n",
    "    batches, batch = [], []\n",
    "    for sample in subsamples:\n",
    "        batch.append(sample)\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_single_label_dir_batchly(file_dir, batch_size, label):\n",
    "    '''\n",
    "    scan .ftr files in file_dir and return (batches, labels)\n",
    "    labels are copies of label\n",
    "    '''\n",
    "    batches, labels, names = [], [], []\n",
    "    old_path = os.getcwd()\n",
    "    os.chdir(file_dir)\n",
    "    \n",
    "    files = suffix_filter(os.listdir(), '.ftr')\n",
    "    for filename in progress(files):\n",
    "        mfcc = load_from_file(filename)\n",
    "        subs = subsampling(mfcc, offset, duration, unit, stride)\n",
    "        new_batches = get_batches(subs, batch_size)\n",
    "        batches += new_batches\n",
    "        labels += [label for _ in new_batches]\n",
    "        names += [filename for _ in new_batches]\n",
    "    \n",
    "    os.chdir(old_path)\n",
    "    return batches, labels, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_dir_batchly(wkdir, batch_size, shuffle=False, random_seed=1273):\n",
    "    '''\n",
    "    wkdir has '/Positive/' and '/Negative/' directory\n",
    "    return batches, labels and descriptions\n",
    "    '''\n",
    "    old_path = os.getcwd()\n",
    "    os.chdir(wkdir)\n",
    "    assert path.exists('Positive')\n",
    "    assert path.exists('Negative')\n",
    "    \n",
    "    p_batches, p_labels, p_names = scan_single_label_dir_batchly('Positive', batch_size, '+')\n",
    "    n_batches, n_labels, n_names = scan_single_label_dir_batchly('Negative', batch_size, '-')\n",
    "    \n",
    "    batches = p_batches + n_batches\n",
    "    labels = p_labels + n_labels\n",
    "    names = p_names + n_names\n",
    "    \n",
    "    if shuffle:\n",
    "        for obj in batches, labels, names:\n",
    "            random.seed(random_seed)\n",
    "            random.shuffle(obj)\n",
    "    \n",
    "    os.chdir(old_path)\n",
    "    return batches, labels, names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../Data/Sounds/yzc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:00, 843.06it/s]\n",
      "32it [00:00, 1071.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(195, 51, 40, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches, train_labels, train_names = scan_dir_batchly('Train/', 51, shuffle=True)\n",
    "show_shape(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_batches`的维度依次是：batch, unit, mfcc, timeframe\n",
    "\n",
    "下面对训练集的每个batch的unit做平均，并压扁频率、时间维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 280)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_units = np.mean(train_batches, axis=1)\n",
    "train_units = [unit.flatten() for unit in train_units]\n",
    "show_shape(train_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面开始训练..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5076923076923077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', gamma=1e-8, C=1.0)\n",
    "clf.fit(train_units, train_labels)\n",
    "clf.score(train_units, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面，在yzc的测试集和zfs的全集上测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入测试数据，用小batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 654.85it/s]\n",
      "4it [00:00, 803.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(259, 5, 40, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_batches, test1_labels, test1_names = scan_dir_batchly('Test/', 5, shuffle=True, random_seed=1)\n",
    "show_shape(test1_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:00, 783.20it/s]\n",
      "35it [00:00, 633.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2590, 5, 40, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_batches, test2_labels, test2_names = scan_dir_batchly('zfs/', 5, shuffle=True, random_seed=13)\n",
    "show_shape(test2_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义投票决策机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batchly(clf, batch):\n",
    "    '''\n",
    "    predict a class label based on in-batch voting\n",
    "    batch-size is suggested to be an odd number\n",
    "    clf: svm classifier\n",
    "    batch: one batch, shape like (xxx, 40, 7)\n",
    "    '''\n",
    "    flattened_batch = [sample.flatten() for sample in batch] # shape (xxx, 280)\n",
    "    votes = clf.predict(flattened_batch)\n",
    "    p_cnt = len(votes[votes == '+'])\n",
    "    n_cnt = len(votes[votes == '-'])\n",
    "    return '+' if p_cnt > n_cnt else '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义评价机制，可以输出错误的情况有哪些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_batches(clf, batches, labels, names=None):\n",
    "    '''\n",
    "    score a classifier's performance on batches\n",
    "    return: acc (float number)\n",
    "    '''\n",
    "    total, correct = len(batches), 0\n",
    "    incorrect_cases = []\n",
    "    if names == None:\n",
    "        for batch, label in zip(batches, labels):\n",
    "            if predict_batchly(clf, batch) == label: correct += 1\n",
    "        return correct / total\n",
    "    else:\n",
    "        for batch, label, name in zip(batches, labels, names):\n",
    "            if predict_batchly(clf, batch) == label:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect_cases.append(name)\n",
    "        return correct / total, incorrect_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1, incorrect_cases1 = score_batches(clf, test1_batches, test1_labels, test1_names)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2, incorrect_cases2 = score_batches(clf, test2_batches, test2_labels, test2_names)\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果不理想，下面将集中调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('yzc/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面两个语句块可以多次反复运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 756.93it/s]\n",
      "4it [00:00, 571.76it/s]\n",
      "35it [00:00, 413.98it/s]\n",
      "35it [00:00, 421.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yzc test size: (644, 3, 40, 9)\n",
      "zfs test size: (3220, 3, 40, 9)\n"
     ]
    }
   ],
   "source": [
    "# 和采样相关的参数\n",
    "offset = int(2000 * FRAME_MS_RATIO) # offset of subsampling, in frames (2s in this eg.) 偏移量\n",
    "duration = int(6000 * FRAME_MS_RATIO) # maximun length of subsampling range, in frames 持续时间\n",
    "unit = int(100 * FRAME_MS_RATIO) # length of a single subsample, in frames 单元窗口长度\n",
    "stride = unit // 2 # step in frames 移动窗口的步长\n",
    "\n",
    "test1_batches, test1_labels, test1_names = scan_dir_batchly('Test/', 3, shuffle=True, random_seed=1)\n",
    "print('yzc test size:', show_shape(test1_batches))\n",
    "\n",
    "test2_batches, test2_labels, test2_names = scan_dir_batchly('../zfs/', 3, shuffle=True, random_seed=13)\n",
    "print('zfs test size:', show_shape(test2_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 599.23it/s]\n",
      "32it [00:00, 535.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (2668, 3, 40, 9) \n",
      "\n",
      "train score:     0.9602698650674663\n",
      "yzc test score:  0.8757763975155279\n",
      "zfs test score:  0.6531055900621118\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 3 # 训练集上的加权规模\n",
    "svm_config = {        # svm 参数\n",
    "    'gamma': 3e-6,\n",
    "    'C': 1.0,\n",
    "    'random_state': 11,\n",
    "    'degree': 4,\n",
    "    'kernel': 'poly'\n",
    "}\n",
    "\n",
    "train_batches, train_labels, train_names = scan_dir_batchly('Train/', train_batch_size, shuffle=True)\n",
    "train_units = np.mean(train_batches, axis=1)\n",
    "train_units = [unit.flatten() for unit in train_units]\n",
    "print('train size:', show_shape(train_batches), '\\n')\n",
    "\n",
    "clf = SVC(**svm_config)\n",
    "clf.fit(train_units, train_labels)\n",
    "print('train score:    ', clf.score(train_units, train_labels))\n",
    "print('yzc test score: ', score_batches(clf, test1_batches, test1_labels))\n",
    "print('zfs test score: ', score_batches(clf, test2_batches, test2_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 在二人混合数据集上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../mixed/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-898e34976e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mixed/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../mixed/'"
     ]
    }
   ],
   "source": [
    "os.chdir('../mixed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 560.02it/s]\n",
      "32it [00:00, 385.31it/s]\n",
      "10it [00:00, 546.83it/s]\n",
      "4it [00:00, 593.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (2668, 3, 40, 9)\n",
      "test size:  (644, 3, 40, 9) \n",
      "\n",
      "train score:  0.9115442278860569\n",
      "test score:   0.8742236024844721\n"
     ]
    }
   ],
   "source": [
    "# 和采样相关的参数\n",
    "offset = int(2000 * FRAME_MS_RATIO) # offset of subsampling, in frames (2s in this eg.) 偏移量\n",
    "duration = int(6000 * FRAME_MS_RATIO) # maximun length of subsampling range, in frames 持续时间\n",
    "unit = int(100 * FRAME_MS_RATIO) # length of a single subsample, in frames 单元窗口长度\n",
    "stride = unit // 2 # step in frames 移动窗口的步长\n",
    "\n",
    "train_batch_size = 3 # 训练集上的加权规模\n",
    "svm_config = {        # svm 参数\n",
    "    'gamma': 5e-6,\n",
    "    'C': 3.0,\n",
    "    'random_state': 11\n",
    "}\n",
    "\n",
    "train3_batches, train3_labels, train3_names = scan_dir_batchly('Train/', train_batch_size, shuffle=True, random_seed=2)\n",
    "train3_units = np.mean(train3_batches, axis=1)\n",
    "train3_units = [unit.flatten() for unit in train3_units]\n",
    "print('train size:', show_shape(train3_batches))\n",
    "\n",
    "test3_batches, test3_labels, test3_names = scan_dir_batchly('Test/', 3, shuffle=True, random_seed=1)\n",
    "print('test size: ', show_shape(test3_batches), '\\n')\n",
    "\n",
    "clf2 = SVC(kernel='rbf', **svm_config)\n",
    "clf2.fit(train3_units, train3_labels)\n",
    "print('train score: ', clf2.score(train3_units, train3_labels))\n",
    "print('test score:  ', score_batches(clf2, test3_batches, test3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用MLP分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8871814092953523\n",
      "test score:   0.8260869565217391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf3 = MLPClassifier(hidden_layer_sizes=(300, 200, 100, 10), activation='relu', learning_rate_init=1e-5)\n",
    "clf3.fit(train3_units, train3_labels)\n",
    "print('train score: ', clf3.score(train3_units, train3_labels))\n",
    "print('test score:  ', score_batches(clf3, test3_batches, test3_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
