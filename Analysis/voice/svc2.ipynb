{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svc训练方案2.0\n",
    "\n",
    "### 训练时对yzc训练集进行大batch的采样，测试时对测试集进行小batch的采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import os.path as path\n",
    "from tqdm import tqdm as progress\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_MS_RATIO = 0.09380235476687636 # frames per milisecond\n",
    "offset = int(2000 * FRAME_MS_RATIO) # offset of subsampling, in frames (2s in this eg.)\n",
    "duration = int(6000 * FRAME_MS_RATIO) # maximun length of subsampling range, in frames\n",
    "unit = int(80 * FRAME_MS_RATIO) # length of a single subsample, in frames\n",
    "stride = unit // 2 # step in frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling from `.ftr` Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO support\n",
    "def load_from_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj\n",
    "\n",
    "def save_to_file(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def suffix_filter(files, suffix):\n",
    "    '''\n",
    "    return list of files with given suffix\n",
    "    '''\n",
    "    return filter(lambda x: x.endswith(suffix), files)\n",
    "\n",
    "def show_shape(obj):\n",
    "    return np.array(obj).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(mfcc: object, offset, duration, unit, stride=None):\n",
    "    '''\n",
    "    mfcc: shape like (40, xxx)\n",
    "    return: list of subsamples\n",
    "    '''\n",
    "    if stride is None: stride = unit // 2\n",
    "    subsamples = []\n",
    "    high = offset + duration\n",
    "    left = offset\n",
    "    right = left + unit\n",
    "    while right <= high:\n",
    "        subsamples.append(mfcc[:, left : right])\n",
    "        left += stride\n",
    "        right += stride\n",
    "    return subsamples\n",
    "\n",
    "def get_batches(subsamples, batch_size):\n",
    "    '''\n",
    "    batch-size is suggested to be an odd number\n",
    "    return a list of test-batches from subsamples\n",
    "    '''\n",
    "    batches, batch = [], []\n",
    "    for sample in subsamples:\n",
    "        batch.append(sample)\n",
    "        if len(batch) == batch_size:\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_single_label_dir_batchly(file_dir, batch_size, label):\n",
    "    '''\n",
    "    scan .ftr files in file_dir and return (batches, labels)\n",
    "    labels are copies of label\n",
    "    '''\n",
    "    batches, labels, names = [], [], []\n",
    "    old_path = os.getcwd()\n",
    "    os.chdir(file_dir)\n",
    "    \n",
    "    files = suffix_filter(os.listdir(), '.ftr')\n",
    "    for filename in progress(files):\n",
    "        mfcc = load_from_file(filename)\n",
    "        subs = subsampling(mfcc, offset, duration, unit, stride)\n",
    "        new_batches = get_batches(subs, batch_size)\n",
    "        batches += new_batches\n",
    "        labels += [label for _ in new_batches]\n",
    "        names += [filename for _ in new_batches]\n",
    "    \n",
    "    os.chdir(old_path)\n",
    "    return batches, labels, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_dir_batchly(wkdir, batch_size, shuffle=False, random_seed=1273):\n",
    "    '''\n",
    "    wkdir has '/Positive/' and '/Negative/' directory\n",
    "    return batches, labels and descriptions\n",
    "    '''\n",
    "    old_path = os.getcwd()\n",
    "    os.chdir(wkdir)\n",
    "    assert path.exists('Positive')\n",
    "    assert path.exists('Negative')\n",
    "    \n",
    "    p_batches, p_labels, p_names = scan_single_label_dir_batchly('Positive', batch_size, '+')\n",
    "    n_batches, n_labels, n_names = scan_single_label_dir_batchly('Negative', batch_size, '-')\n",
    "    \n",
    "    batches = p_batches + n_batches\n",
    "    labels = p_labels + n_labels\n",
    "    names = p_names + n_names\n",
    "    \n",
    "    if shuffle:\n",
    "        for obj in batches, labels, names:\n",
    "            random.seed(random_seed)\n",
    "            random.shuffle(obj)\n",
    "    \n",
    "    os.chdir(old_path)\n",
    "    return batches, labels, names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../Data/Sounds/yzc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:00, 808.09it/s]\n",
      "32it [00:00, 786.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(195, 51, 40, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches, train_labels, train_names = scan_dir_batchly('Train/', 51, shuffle=True)\n",
    "show_shape(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_batches`的维度依次是：batch, unit, mfcc, timeframe\n",
    "\n",
    "下面对训练集的每个batch的unit做平均，并压扁频率、时间维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 280)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_units = np.mean(train_batches, axis=1)\n",
    "train_units = [unit.flatten() for unit in train_units]\n",
    "show_shape(train_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面开始训练..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5076923076923077"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', gamma=1e-8, C=1.0)\n",
    "clf.fit(train_units, train_labels)\n",
    "clf.score(train_units, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面，在yzc的测试集和zfs的全集上测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入测试数据，用小batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 713.32it/s]\n",
      "4it [00:00, 699.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(259, 5, 40, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_batches, test1_labels, test1_names = scan_dir_batchly('Test/', 5, shuffle=True, random_seed=1)\n",
    "show_shape(test1_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yzc', '.DS_Store', '.vtdata', 'zfs', '.backup', '.nomedia']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:00, 696.05it/s]\n",
      "35it [00:00, 636.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2590, 5, 40, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_batches, test2_labels, test2_names = scan_dir_batchly('zfs/', 5, shuffle=True, random_seed=13)\n",
    "show_shape(test2_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义投票决策机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batchly(clf, batch):\n",
    "    '''\n",
    "    predict a class label based on in-batch voting\n",
    "    batch-size is suggested to be an odd number\n",
    "    clf: svm classifier\n",
    "    batch: one batch, shape like (xxx, 40, 7)\n",
    "    '''\n",
    "    flattened_batch = [sample.flatten() for sample in batch] # shape (xxx, 280)\n",
    "    votes = clf.predict(flattened_batch)\n",
    "    p_cnt = len(votes[votes == '+'])\n",
    "    n_cnt = len(votes[votes == '-'])\n",
    "    return '+' if p_cnt > n_cnt else '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义评价机制，可以输出错误的情况有哪些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_batches(clf, batches, labels, names=None):\n",
    "    '''\n",
    "    score a classifier's performance on batches\n",
    "    return: acc (float number)\n",
    "    '''\n",
    "    total, correct = len(batches), 0\n",
    "    incorrect_cases = []\n",
    "    if names == None:\n",
    "        for batch, label in zip(batches, labels):\n",
    "            if predict_batchly(clf, batch) == label: correct += 1\n",
    "        return correct / total\n",
    "    else:\n",
    "        for batch, label, name in zip(batches, labels, names):\n",
    "            if predict_batchly(clf, batch) == label:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect_cases.append(name)\n",
    "        return correct / total, incorrect_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1, incorrect_cases1 = score_batches(clf, test1_batches, test1_labels, test1_names)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2, incorrect_cases2 = score_batches(clf, test2_batches, test2_labels, test2_names)\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果不理想，下面将集中调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('yzc/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面两个语句块可以多次反复运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 1069.88it/s]\n",
      "4it [00:00, 1827.19it/s]\n",
      "35it [00:00, 1554.99it/s]\n",
      "35it [00:00, 1243.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yzc test size: (189, 5, 40, 9)\n",
      "zfs test size: (1890, 5, 40, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 和采样相关的参数\n",
    "offset = int(2000 * FRAME_MS_RATIO) # offset of subsampling, in frames (2s in this eg.) 偏移量\n",
    "duration = int(6000 * FRAME_MS_RATIO) # maximun length of subsampling range, in frames 持续时间\n",
    "unit = int(100 * FRAME_MS_RATIO) # length of a single subsample, in frames 单元窗口长度\n",
    "stride = unit // 2 # step in frames 移动窗口的步长\n",
    "\n",
    "test1_batches, test1_labels, test1_names = scan_dir_batchly('Test/', 5, shuffle=True, random_seed=1)\n",
    "print('yzc test size:', show_shape(test1_batches))\n",
    "\n",
    "test2_batches, test2_labels, test2_names = scan_dir_batchly('../zfs/', 5, shuffle=True, random_seed=13)\n",
    "print('zfs test size:', show_shape(test2_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:00, 1746.02it/s]\n",
      "32it [00:00, 1437.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (780, 11, 40, 9) \n",
      "\n",
      "train score:     0.8179487179487179\n",
      "yzc test score:  0.7566137566137566\n",
      "zfs test score:  0.7126984126984127\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 11 # 训练集上的加权规模\n",
    "svm_config = {        # svm 参数\n",
    "    'gamma': 1e-6,\n",
    "    'C': 1,\n",
    "    'random_state': 10\n",
    "}\n",
    "\n",
    "train_batches, train_labels, train_names = scan_dir_batchly('Train/', train_batch_size, shuffle=True)\n",
    "train_units = np.mean(train_batches, axis=1)\n",
    "train_units = [unit.flatten() for unit in train_units]\n",
    "print('train size:', show_shape(train_batches), '\\n')\n",
    "\n",
    "clf = SVC(kernel='rbf', **svm_config)\n",
    "clf.fit(train_units, train_labels)\n",
    "print('train score:    ', clf.score(train_units, train_labels))\n",
    "print('yzc test score: ', score_batches(clf, test1_batches, test1_labels))\n",
    "print('zfs test score: ', score_batches(clf, test2_batches, test2_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
