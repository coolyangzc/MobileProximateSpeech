{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # todo this is important\n",
    "os.chdir('/Users/james/MobileProximateSpeech/Analysis')\n",
    "sys.path.append('/Users/james/MobileProximateSpeech/Analysis')\n",
    "\n",
    "from utils.logger import DualLogger\n",
    "from utils.tools import date_time\n",
    "from utils.voice_preprocess.mfcc_data_loader import DataPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "\t'''\n",
    "\tcompute f1 score\n",
    "\t'''\n",
    "\ty_pred = K.round(y_pred)\n",
    "\ttp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "\t# tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "\tfp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "\tfn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "\tp = tp / (tp + fp + K.epsilon())\n",
    "\tr = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "\tf1 = 2 * p * r / (p + r + K.epsilon())\n",
    "\tf1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\treturn K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP_model():\n",
    "\tprint('building MLP model...')\n",
    "\thidden_layer_sizes = (300, 200, 100, 10)\n",
    "\tmodel = Sequential([\n",
    "\t\t# layers.Flatten(input_shape=(9, 40)),\n",
    "\t\tlayers.Dense(units=hidden_layer_sizes[0], activation='relu', input_dim=360),\n",
    "\t\tlayers.Dense(units=hidden_layer_sizes[1], activation='relu'),\n",
    "\t\tlayers.Dense(units=hidden_layer_sizes[2], activation='relu'),\n",
    "\t\tlayers.Dense(units=hidden_layer_sizes[3], activation='relu'),\n",
    "\t\tlayers.Dense(units=1, activation='sigmoid'),\n",
    "\t])\n",
    "\n",
    "\topt = optimizers.Adam(lr=1e-5, decay=0.)\n",
    "\tmodel.compile(optimizer=opt, loss='mse', metrics=['acc', f1])\n",
    "\tprint('built.')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def build_CNN_model():\n",
    "\tprint('building CNN model...')\n",
    "\tmodel = Sequential([\n",
    "\t\tlayers.Conv1D(input_shape=(9, 24), filters=3, kernel_size=(3,)),\n",
    "\t\tlayers.Activation('relu'),\n",
    "\t\tlayers.MaxPool1D(pool_size=2),\n",
    "\t\tlayers.Flatten(),\n",
    "\t\tlayers.Dense(units=10),\n",
    "\t\tlayers.Activation('relu'),\n",
    "\t\tlayers.Dense(units=1),\n",
    "\t\tlayers.Activation('sigmoid')\n",
    "\t])\n",
    "\n",
    "\topt = optimizers.Adam(lr=0.0003, decay=1e-3)\n",
    "\tmodel.compile(optimizer=opt, loss='mse', metrics=['acc', f1])\n",
    "\tprint('built.')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def build_RNN_model():\n",
    "\tprint('building RNN model...')\n",
    "\tlayer_units = (24, 200, 20, 1)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(layers.GRU(units=layer_units[1], activation='tanh',\n",
    "\t\t\t\t\t\t return_sequences=False, input_shape=(None, layer_units[0])))\n",
    "\tmodel.add(layers.Dropout(0.2))\n",
    "\tmodel.add(layers.Dense(units=layer_units[2], activation='relu'))\n",
    "\tmodel.add(layers.Dropout(0.2))\n",
    "\tmodel.add(layers.Dense(units=layer_units[3], activation='sigmoid'))\n",
    "\n",
    "\topt = optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.001)\n",
    "\tmodel.compile(optimizer=opt, loss='mse', metrics=['acc', f1])\n",
    "\tprint('built.')\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def load_train_test(wkdir, chunks=False, test_size=None):\n",
    "\tdataset = DataPack()\n",
    "\tif chunks == True:\n",
    "\t\tdataset.from_chunks_dir(wkdir)\n",
    "\telse:\n",
    "\t\tdataset.from_wav_dir(wkdir)\n",
    "\tdataset.apply_subsampling()\n",
    "\tdataset.roll_f_as_last()\n",
    "\tprint('shape like:')\n",
    "\tdataset.show_shape()\n",
    "\tprint('data loaded.\\n')\n",
    "\treturn dataset.train_test_split(test_size=test_size)\n",
    "\n",
    "\n",
    "def plot_history(which='acc'):\n",
    "\tglobal history, DATETIME\n",
    "\tplt.plot(history.history[which])\n",
    "\tplt.plot(history.history['val_%s' % which])\n",
    "\tplt.title('Model %s' % which)\n",
    "\tplt.ylabel(('%s' % which).upper())\n",
    "\tplt.xlabel('Epoch')\n",
    "\tplt.legend(['Train', 'Val'], loc='upper left')\n",
    "\tplt.savefig('outputs/%s%s.png' % (DATETIME, which))\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def scikit_clf(train, test):\n",
    "\tfrom sklearn.neural_network import MLPClassifier\n",
    "\tclf = MLPClassifier(hidden_layer_sizes=(300, 200, 100, 10),\n",
    "\t\t\t\t\t\tactivation='relu', solver='adam',\n",
    "\t\t\t\t\t\tlearning_rate_init=1e-5, verbose=True, shuffle=True)\n",
    "\tprint('clf ready.\\n', clf)\n",
    "\tprint()\n",
    "\tclf.fit(train.data, train.labels)\n",
    "\tprint('\\ntrain over.\\n')\n",
    "\ttrain_acc = clf.score(train.data, train.labels)\n",
    "\tprint('train acc =', train_acc)\n",
    "\tval_acc = clf.score(test.data, test.labels)\n",
    "\tprint('val acc =', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_which_model = {\n",
    "\t'RNN': build_RNN_model,\n",
    "\t'CNN': build_CNN_model,\n",
    "\t'MLP': build_MLP_model\n",
    "}\n",
    "\n",
    "wkdirs = [\n",
    "\t'Data/Study3/subjects/yzc/trimmed',\n",
    "\t'Data/Study3/subjects/0305_1/trimmed',\n",
    "\t'Data/Study3/subjects/0305_2/trimmed',\n",
    "\t'Data/Study3/subjects/cjr/trimmed',\n",
    "\t'Data/Study3/subjects/gfz/trimmed',\n",
    "\t'Data/Study3/subjects/wty/trimmed',\n",
    "\t'Data/Study3/subjects/wwn/trimmed',\n",
    "\t'Data/Study3/subjects/xy/trimmed',\n",
    "\t# 'Data/Study3/subjects/wj/trimmed',\n",
    "]\n",
    "\n",
    "valdir = 'Data/Study3/subjects/zfs/trimmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:02,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape like:\n",
      "data: (23368, 9, 24)\n",
      "labels: (23368,)\n",
      "names: (23368,)\n",
      "test shape like:\n",
      "data: (2676, 9, 24)\n",
      "labels: (2676,)\n",
      "names: (2676,)\n"
     ]
    }
   ],
   "source": [
    "train = DataPack()\n",
    "train.from_chunks_dir(wkdirs)\n",
    "train.apply_subsampling()\n",
    "# train.to_flatten()\n",
    "train.roll_f_as_last()\n",
    "print('train shape like:')\n",
    "train.data = train.data\n",
    "train.labels = train.labels\n",
    "train.show_shape()\n",
    "\n",
    "test = DataPack()\n",
    "test.from_chunks_dir(valdir)\n",
    "test.apply_subsampling()\n",
    "# test.to_flatten()\n",
    "test.roll_f_as_last()\n",
    "print('test shape like:')\n",
    "test.show_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.logger.DualLogger at 0x1c362084a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building RNN model...\n",
      "built.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 200)               135000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 139,041\n",
      "Trainable params: 139,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "building RNN model...\n",
      "built.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 200)               135000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 139,041\n",
      "Trainable params: 139,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 2754/23368 [==>...........................] - ETA: 6:58 - loss: 0.2613 - acc: 0.5127 - f1: 0.4633"
     ]
    }
   ],
   "source": [
    "model_type = 'RNN'\n",
    "\n",
    "os.path.exists('model_state')\n",
    "DATETIME = date_time()\n",
    "DualLogger('logs/%s%s.txt' % (DATETIME, model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_which_model[model_type]()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1ae508f9d664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# scikit_clf(train, test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scikit_clf(train, test)\n",
    "\n",
    "history = model.fit(train.data, train.labels, batch_size=1, epochs=10, verbose=1)\n",
    "train_loss, train_acc, train_f1 = model.evaluate(train.data, train.labels, batch_size=10)\n",
    "test_loss, test_acc, test_f1 = model.evaluate(test.data, test.labels, batch_size=10)\n",
    "\n",
    "print('acc, f1 on train:', train_acc, train_f1)\n",
    "print('acc, f1 on test :', test_acc, test_f1)\n",
    "\n",
    "model.save('voice/model_state/%s%s %d-%d.h5' % (DATETIME, model_type, train_acc * 100, test_acc * 100))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plot_history('acc')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plot_history('loss')\n",
    "\n",
    "# Plot training & validation f1 values\n",
    "plot_history('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
